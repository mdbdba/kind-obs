---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: inner-aggregator-vector
  namespace: flux-system
spec:
  targetNamespace: telemetry
  chart:
    spec:
      chart: vector
      sourceRef:
        kind: HelmRepository
        name: vector
      version: 0.41.0
  interval: 10m0s
  values:
    fullnameOverride: "inner-aggregator"
    role: "Stateless-Aggregator"
    customConfig:
      sources:
        kafka_input:
          type: "kafka"
          bootstrap_servers: "kafka-kafka-brokers.queuing.svc:9092"
          topics: [ "telemetry-logs" ] # Or use wildcard "grafana.*" if needed
          group_id: "vector-aggregator"
          auto_offset_reset: "earliest"
          decoding:
            codec: "json"

      transforms:
        # Process and tag incoming data
        process_telemetry:
          type: "remap"
          inputs: [ "kafka_input" ]
          source: |
            # Add aggregator metadata
            .aggregator_timestamp = now()
            
            # Set default values for important fields if they don't exist
            if !exists(.kubernetes.namespace) {
              .kubernetes.namespace = .namespace ?? "unknown"
            }
            
            if !exists(.kubernetes.pod_name) {
              .kubernetes.pod_name = .pod_name ?? .pod ?? "unknown"
            }
            
            # Extract log level if possible
            if !exists(.level) && exists(.message) && is_string(.message) {
              # Look for common log level patterns
              if match(to_string(.message), r'(?i)\b(ERROR|WARN|INFO|DEBUG)\b') {
                matches = parse_regex(to_string(.message), r'(?i)\b(ERROR|WARN|INFO|DEBUG)\b')
                if exists(matches[1]) {
                  .level = upcase(matches[1])
                }
              }
            }
            
            # Ensure we have a timestamp field for Loki
            if !exists(.timestamp) {
              .timestamp = .aggregator_timestamp
            }
            
            # Create labels for Loki
            # The namespace and app labels are crucial for querying
            .labels = {}
            .labels.host = .host ?? "unknown"
            
            if exists(.kubernetes) {
              .labels.namespace = .kubernetes.namespace
              .labels.pod = .kubernetes.pod_name
            
              if exists(.kubernetes.container_name) {
                .labels.container = .kubernetes.container_name
                .labels.app = .kubernetes.container_name
              }
            }
            
            if exists(.level) {
              .labels.level = .level
            }

      sinks:
        # Loki for logs
        loki_output:
          type: "loki"
          inputs: ["process_telemetry"]
          endpoint: "http://monitoring-lgtm-loki-gateway.monitoring.svc:80"
          encoding:
            codec: "json"
          labels:
            namespace: '{{`{{ kubernetes.namespace }}`}}'
            pod: '{{`{{ kubernetes.pod_name }}`}}'
            container: '{{`{{ kubernetes.container_name }}`}}'
            host: '{{`{{ host }}`}}'
            level: '{{`{{ level }}`}}'

          out_of_order_action: "accept"  # Handle logs arriving out of order
          batch:
            max_bytes: 1048576           # 1MB
            timeout_secs: 1
          remove_label_fields: false      # Don't remove fields used for labels
          healthcheck:
            enabled: true

        # Debug sink - useful during setup and testing
        console:
          type: "console"
          inputs: [ "process_telemetry" ]
          encoding:
            codec: "json"

    # Create a PVC for data persistence
    persistence:
      enabled: true
      size: 10Gi

    service:
      enabled: true
      type: ClusterIP

    replicas: 2
    resources:
      requests:
        memory: "512Mi"
        cpu: "200m"
      limits:
        memory: "1Gi"
        cpu: "1000m"