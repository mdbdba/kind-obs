---
apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: inner-aggregator-vector
  namespace: flux-system
spec:
  targetNamespace: telemetry
  chart:
    spec:
      chart: vector
      sourceRef:
        kind: HelmRepository
        name: vector
      version: 0.41.0
  interval: 10m0s
  values:
    fullnameOverride: "inner-aggregator"
    role: "Stateless-Aggregator"
    customConfig:
      sources:
        kafka_input:
          type: "kafka"
          bootstrap_servers: "kafka-kafka-brokers.queuing.svc:9092"
          topics: [ "telemetry-logs" ] # Or use wildcard "grafana.*" if needed
          group_id: "vector-aggregator"
          auto_offset_reset: "earliest"
          decoding:
            codec: "json"

      transforms:
        # Process and tag incoming data
        process_telemetry:
          type: "remap"
          inputs: [ "kafka_input" ]
          source: |
            # Add aggregator timestamp for measuring throughput
            .aggregator_timestamp = now()
            
            # Ensure kubernetes object exists - it should from edge, but just in case
            if !exists(.kubernetes) {
              .kubernetes = {}
            }
            
            # Ensure critical fields exist with sensible defaults
            if !exists(.kubernetes.namespace) {
              .kubernetes.namespace = "unknown"
            }
            
            if !exists(.kubernetes.pod_name) {
              .kubernetes.pod_name = "unknown"
            }
            
            if !exists(.kubernetes.container_name) {
              .kubernetes.container_name = "unknown"
            }
            
            # Ensure we have a host field
            if !exists(.host) {
              .host = "unknown"
            }
            
            # Extract log level if not already done
            if !exists(.level) && exists(.message) {
              if is_string(.message) {
                message_str = string!(.message)
                if match!(message_str, r'(?i)\b(ERROR|WARN|INFO|DEBUG)\b') {
                  matches = parse_regex!(message_str, r'(?i)\b(ERROR|WARN|INFO|DEBUG)\b')
                  if exists(matches[1]) {
                    .level = upcase(matches[1])
                  }
                }
              }
            }
            
            # Default level if not set
            if !exists(.level) {
              .level = "unknown"
            }
            
            # Original timestamp should be preserved from edge, but just in case
            if !exists(.timestamp) {
              .timestamp = .aggregator_timestamp
            }

      sinks:
        # Loki for logs
        loki_output:
          type: "loki"
          inputs: ["process_telemetry"]
          endpoint: "http://monitoring-lgtm-loki-gateway.monitoring.svc:80"
          encoding:
            codec: "json"
          labels:
            namespace: '{{`{{ kubernetes.namespace }}`}}'
            pod: '{{`{{ kubernetes.pod_name }}`}}'
            container: '{{`{{ kubernetes.container_name }}`}}'
            host: '{{`{{ host }}`}}'
            level: '{{`{{ level }}`}}'

          out_of_order_action: "accept"  # Handle logs arriving out of order
          batch:
            max_bytes: 1048576           # 1MB
            timeout_secs: 1
          remove_label_fields: false      # Don't remove fields used for labels
          healthcheck:
            enabled: true

        # Debug sink - useful during setup and testing
        console:
          type: "console"
          inputs: [ "process_telemetry" ]
          encoding:
            codec: "json"

    # Create a PVC for data persistence
    persistence:
      enabled: true
      size: 10Gi

    service:
      enabled: true
      type: ClusterIP
      ports:
        - name: metrics
          port: 9598
          targetPort: metrics
          protocol: TCP
        - name: api
          port: 8686
          targetPort: api
          protocol:

    containerPorts:
      - name: metrics
        containerPort: 9598
        protocol: TCP
      - name: api
        containerPort: 8686
        protocol: TCP


    replicas: 2
    resources:
      requests:
        memory: "512Mi"
        cpu: "200m"
      limits:
        memory: "1Gi"
        cpu: "1000m"